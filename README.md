### brains_q3(5位)
[第5回fujifilm brains コンテスト](https://fujifilmdatasciencechallnge.mystrikingly.com/)を進める際に実行したことのまとめです。

<br>

#### 特徴量の扱いについて
1. 与えられたデータセットはsmiles文字列のみ
2. smilesから構造式に変換できる[サイト](http://www.cheminfo.org/flavor/malaria/Utilities/SMILES_generator___checker.html) があったので、それらを利用して構造を確認しました。
3. 2の作業により小さな分子から巨大な分子が含まれていることが確認できました。(少し意外だったのは大きな分子ほどtarget(IC50)の値が大きくなるものが多かった。)
4. 正直なところ、構造式を確認してもtargetの値に寄与する特徴は自分ではわかりませんでした。特定の官能基や部分構造の寄与というより、むしろ分子の形や部分構造同士の相互作用などが重要になるのではと感じました。
5. 上の通りに考えた結果、効果的な特徴量を自分で考えるのは難しいと感じたため中盤以降はモデル部分に注力しました。
6. 序盤はrdkitで拡張したデータのみを学習に使いました。途中からrdkit+mordredで拡張したデータを学習に使うつもりでしたが、制限時間オーバーになったので終盤はより多くのデータが得られるmordredのみを使いました（しかし上位の方の話によると、両方使っても制限時間内での実行は可能だったとのこと）
7. mordredはimportの際にエラーにより上手く機能しなかったので、コンペ中盤以降はmordredディレクトリをanaconda cloudからダウンロードしてsrcディレクトリ中に置いたところ解決しました。
8. mordredは2000個の特徴量が作れますが、約200個くらいは全てNaNの列でした。さらに全体的にNaNを含む特徴量が多いので、mordredだけで拡張したデータを扱うのは適切ではなかったかもしれません。(sklearnのNNを使うときはrdkitにより得たデータの方がCVは良かった)
9. 序盤はQ2で作成した特徴量(水溶性置換基の有無や分子の対称性や芳香族性などを反映したもの)をそのまま使っていました。当然ながらあまり効かなかったので、途中からこれらの特徴量は除きました。
10. lightgbmで学習して重要度の高い特徴量を取り出し、それをもとに加減乗除した特徴量をいくつか加えました。(xfeat？なるライブラリが便利らしい)
11. MACCSやmorganフィンガープリントにより特徴量が生成でき、それの類似度の計算ができますが、CVへの貢献が小さく計算時間が長いことから後半は使いませんでした。
12. これらの理由から、終盤ではmordredにより得たデータとその一部を加減乗除したデータから重要度の高い200個くらいの特徴量を学習に使いました


<br><br>

#### 使用したモデル
1. 序盤からlightgbmをずっと使っていました。過学習を避けたかったので序盤はnum_leaves=5あたりで小さめにしてlr=0.05, epoch=3000で固定していました(他のパラメータはデフォルト)
2. 序盤からboosting_type='gbdt'にしていました。'dart'も試したところスコアが悪化したので後半は使いませんでした。
3. 他の学習モデルにはrandom forestやxgboost、sklearnに含まれるニューラルネットワークや線形モデルを使用しました。
4. 上のモデルのスコアはどれもlightgbmのスコアより悪く、加重平均によるアンサンブルに使用しましたがlightgbm単一の方が良かったです
5. 種々のモデルを用いて線形モデルまたはlightgbmによるスタッキングも試みたが、過学習によりLBがかなり悪化したため終盤はlightgbmのみを使いました。
6. seedの値を変えてアンサンブルも試しましたが、スコアの推移とモデルの容量との兼ね合いから、終盤は単一のseedで8fold lightgbmのモデルを提出しました
7. 中盤以降、スコアを確認しながらnum_leavesを少しずつ大きくしました。最終的にはnum_leaves=12で探索していました。
8. 筆者がパラメータについてよく理解していないこともあり、終盤でのlightgbmのパラメータ探索では以上のことに加えて過学習を防ぐ目的でmax_binを大きくしただけのモデルを提出していました。その他のパラメータは理解しないまま変更するとCVが悪化したため、デフォルトのままにしていました。またlearning_rate=0.01にしてepoch=10000くらいにすると、モデルの容量が制約を大幅に超えてしまいました。そのため制約を超えない程度にlearning_rateを変更して試したところ、learning_rate=0.015に落ち着きました。結果としてはこれらのパラメータの変更だけで終盤のスコアは大きく伸びました。
9. deepchemも使いたかったのでsrcディレクトリに置くなどして色々試しました。ローカルでは上手く使えましたが提出したところエラーが止まらなかったのでdeepchemの使用は泣く泣く諦めました。

<br>

![終盤での進め方](./asset/process.png)

<br><br>

#### その他
1. lightgbmやxgboostを使用する際に欠損値を埋めない方がCVとtrack上のスコアは良かったです
2. Kaggle本にも書いてある調和平均や幾何平均を試したところtrack上のスコアが0.01程度改善する場合が多々あったので試してみる価値はあるかもしれません。
3. サンプルコードではtargetの値にnp.log1pを取ったものを学習に使っていたが、np.log1pを取ったものを正規分布状へ変形させることや元のtargetに対してnp.sqrt()やnp.sqrt(np.log1p())などによる変形を試しました。しかし悉くCVが悪化したので以降使いませんでした。

<br><br>


####  感想と反省
1. 制限時間の兼ね合いからmordredのみのデータを使っていましたが、1位の方はrdkit+mordred+Fingerprintによる特徴量が使えていたので自分ももっといろいろ試してみるべきだったと思います。
2. Q2含めてですがtanimoto係数による類似度の測定を全ての分子同士で計算させていませんでした。これも勝手に自分で計算時間を見積もって判断してしまったためであり大きな反省点です。
3. やはり色々試してみるのが一番良いというのが改めて感じました。
4. 序盤はすぐ最高スコアを更新できるだろうとの考えから、良いスコアを取った特徴量作成用のファイルやモデルをすぐ捨てていました。結果的に序盤の自分のベストスコアが超えれず、かなり苦労したのでファイルの管理は適切に行うべきだと思います（自戒）
5. 訓練データ量が小さく、またCVとLBの乖離が小さかった点で様々な手法を試すことができたコンペでした。非常に勉強になりました。運営の皆様ありがとうございました。

